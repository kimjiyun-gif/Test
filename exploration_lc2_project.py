# -*- coding: utf-8 -*-
"""Exploration_lc2  project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-lLH-e77BPas6h19ndcU54mgpiATh_EC

# 프로젝트 (1) load_digits : 손글씨를 분류해보기

## 데이터 준비
"""

from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# 데이터 준비

digit = load_digits()
digit_data = digit.data
digit_labels = digit.target

digit_data.shape, digit_labels.shape

print(dir(digit))

digit.keys()

digit_labels

digit.target_names

digit.DESCR

"""## 데이터 분리"""

# train, test data 분리

train_input, test_input, train_target, test_target = train_test_split(
    digit_data,
    digit_labels,
    test_size = 0.2,
    random_state = 21
)

print("train_input의 shape:", train_input.shape)
print("test_input의 shape:", test_input.shape)
print("train_target의 shape:", train_target.shape)
print("test_target의 shape:", test_target.shape)

"""## 모델 학습 및 평가"""

# 다양한 모델로 학습하기

# Decision Tree

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

tree_model = DecisionTreeClassifier()
tree_model.fit(train_input, train_target)
test_pred = tree_model.predict(test_input)
accuracy = accuracy_score(test_target, test_pred)
print(accuracy)

print(classification_report(test_target, test_pred))

# Random Forest

from sklearn.ensemble import RandomForestClassifier

rand_model = RandomForestClassifier()
rand_model.fit(train_input, train_target)
test_pred = rand_model.predict(test_input)
accuracy = accuracy_score(test_target, test_pred)
print(accuracy)

print(classification_report(test_target, test_pred))

# SVM

from sklearn import svm

svm_model = svm.SVC()
svm_model.fit(train_input, train_target)
test_pred = svm_model.predict(test_input)
accuracy = accuracy_score(test_target, test_pred)
print(accuracy)

print(classification_report(test_target, test_pred))

# SGDClassifier

from sklearn.linear_model import SGDClassifier

sgd_model = SGDClassifier()
sgd_model.fit(train_input, train_target)
test_pred = sgd_model.predict(test_input)
accuracy = accuracy_score(test_target, test_pred)
print(accuracy)

print(classification_report(test_target, test_pred))

# LogisticRegression

from sklearn.linear_model import LogisticRegression

logistic_model = LogisticRegression()
logistic_model.fit(train_input, train_target)
test_pred = logistic_model.predict(test_input)
accuracy = accuracy_score(test_target, test_pred)
print(accuracy)

print(classification_report(test_target, test_pred))

# 위의 결과로 미루어보아 손글씨를 분류하는 모델로서는 SVM모델이 가장 적합한것 같다.

"""# 프로젝트 (2) load_wine : 와인을 분류해 보자

## 데이터 준비
"""

from sklearn.datasets import load_wine
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# 데이터 준비

wine = load_wine()
wine_data = wine.data
wine_labels = wine.target

wine_data.shape, wine_labels.shape

print(dir(wine))

wine.feature_names

wine.target

wine.target_names

wine.DESCR

"""## 데이터 분리"""

train_input, test_input, train_target, test_target = train_test_split(
    wine_data,
    wine_labels,
    test_size = 0.2,
    random_state = 21
)

print("train_input의 shape:", train_input.shape)
print("test_input의 shape:", test_input.shape)
print("train_target의 shape:", train_target.shape)
print("test_target의 shape:", test_target.shape)

"""## 모델 학습 및 평가"""

# Decision Tree

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

tree_model = DecisionTreeClassifier()
tree_model.fit(train_input, train_target)
test_pred = tree_model.predict(test_input)
accuracy = accuracy_score(test_target, test_pred)
print(accuracy)

print(classification_report(test_target, test_pred))

# Random Forest

from sklearn.ensemble import RandomForestClassifier

rand_model = RandomForestClassifier()
rand_model.fit(train_input, train_target)
test_pred = rand_model.predict(test_input)
accuracy = accuracy_score(test_target, test_pred)
print(accuracy)

print(classification_report(test_target, test_pred))

# SVM

from sklearn import svm

svm_model = svm.SVC()
svm_model.fit(train_input, train_target)
test_pred = svm_model.predict(test_input)
accuracy = accuracy_score(test_target, test_pred)
print(accuracy)

print(classification_report(test_target, test_pred))

# SGDClassifier

from sklearn.linear_model import SGDClassifier

sgd_model = SGDClassifier()
sgd_model.fit(train_input, train_target)
test_pred = sgd_model.predict(test_input)
accuracy = accuracy_score(test_target, test_pred)
print(accuracy)

print(classification_report(test_target, test_pred))

# LogisticRegression

from sklearn.linear_model import LogisticRegression

logistic_model = LogisticRegression()
logistic_model.fit(train_input, train_target)
test_pred = logistic_model.predict(test_input)
accuracy = accuracy_score(test_target, test_pred)
print(accuracy)

print(classification_report(test_target, test_pred))

# 위의 결과를 보아 RandomForestClassifier, LogisticRegression 두 모델의 성능이 가장 높게 나왔다.

"""# 프로젝트 (3) load_breast_cancer : 유방암 여부를 진단해 보자

## 데이터 준비
"""

from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# 데이터 준비

cancer = load_breast_cancer()
cancer_data = cancer.data
cancer_labels = cancer.target

cancer_data.shape, cancer_labels.shape

print(dir(cancer))

cancer.feature_names

cancer.target_names

cancer.target

cancer.DESCR

"""## 데이터 분리"""

train_input, test_input, train_target, test_target = train_test_split(
    cancer_data,
    cancer_labels,
    test_size = 0.2,
    random_state = 21
)

print("train_input의 shape:", train_input.shape)
print("test_input의 shape:", test_input.shape)
print("train_target의 shape:", train_target.shape)
print("test_target의 shape:", test_target.shape)

"""## 모델 학습 및 평가"""

# Decision Tree

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

tree_model = DecisionTreeClassifier()
tree_model.fit(train_input, train_target)
test_pred = tree_model.predict(test_input)
accuracy = accuracy_score(test_target, test_pred)
print(accuracy)

print(classification_report(test_target, test_pred))

# Random Forest

from sklearn.ensemble import RandomForestClassifier

rand_model = RandomForestClassifier()
rand_model.fit(train_input, train_target)
test_pred = rand_model.predict(test_input)
accuracy = accuracy_score(test_target, test_pred)
print(accuracy)

print(classification_report(test_target, test_pred))

# SVM

from sklearn import svm

svm_model = svm.SVC()
svm_model.fit(train_input, train_target)
test_pred = svm_model.predict(test_input)
accuracy = accuracy_score(test_target, test_pred)
print(accuracy)

print(classification_report(test_target, test_pred))

# SGDClassifier

from sklearn.linear_model import SGDClassifier

sgd_model = SGDClassifier()
sgd_model.fit(train_input, train_target)
test_pred = sgd_model.predict(test_input)
accuracy = accuracy_score(test_target, test_pred)
print(accuracy)

print(classification_report(test_target, test_pred))

# LogisticRegression

from sklearn.linear_model import LogisticRegression

logistic_model = LogisticRegression()
logistic_model.fit(train_input, train_target)
test_pred = logistic_model.predict(test_input)
accuracy = accuracy_score(test_target, test_pred)
print(accuracy)

print(classification_report(test_target, test_pred))

# 위의 결과로 보아 RandomForestClassifier의 성능이 가장 좋게 나왔다.
# 프로젝트(1),(2),(3)을 진행해본 결과 전반적으로 RandomForestClassifier의 성능이 가장 좋았음을 알 수 있었다.